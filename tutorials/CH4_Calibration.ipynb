{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "\n",
    "TUTORIAL_DIR = Path(os.getcwd()).as_posix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of Building Energy Simulation — Tutorial\n",
    "\n",
    "This notebook serves as a guided tutorial for understanding and applying a systematic calibration methodology to building energy models. The approach is based on the FiabGP project and is implemented using the open-source Python module [energytool](https://github.com/BuildingEnergySimulationTools/energytool), which interfaces with EnergyPlus simulations.\n",
    "\n",
    "We will go step-by-step through the key stages of a real-world calibration process, from raw measurements to final simulation error analysis, including:\n",
    "\n",
    "- **Understanding the role of calibration** in building performance modeling\n",
    "- **Assessing the initial simulation error** using standard metrics such as NMBE and CV(RMSE)\n",
    "- **Adjusting the model using measured data** (temperature, weather, usage)\n",
    "- **Identifying key uncertain parameters** through global sensitivity analysis (Morris method)\n",
    "- **Performing model calibration** using optimization algorithms\n",
    "- **Interpreting the results** to assess model validity and limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The methodology is applied to a real 7-story multifamily building located in *Pessac*, France. As part of a large-scale renovation project, a measurement campaign was carried out from **September 2021 to July 2022** in four monitored apartments.\n",
    "\n",
    "## Project context:\n",
    "\n",
    "- **Thermal envelope renovation** using different types of insulation (resol, rockwool 160–300 mm)\n",
    "- **Replacement of windows** (double glazing)\n",
    "- **Mechanical ventilation system (VMC)** installed\n",
    "- **Infiltration tests** showing improved airtightness\n",
    "- **Sensors installed** to measure:\n",
    "  - Indoor temperature (living room & bedroom)\n",
    "  - Gas consumption\n",
    "  - Heating power delivered (space heating & DHW)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|             Figure 1: Building model sketch              |                 Figure 2: Building measurement overview                  |\n",
    "|:-------------------------------------------------------------:|:---------------------------------------------------------------:|\n",
    "| <img height=\"300\" src=\"resources/building.png\"/> | <img src=\"resources/measurements.png\"  height=\"300\"> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and set model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "boundaries = pd.read_csv(\n",
    "    Path(TUTORIAL_DIR) / \"resources/mean_temp_heating.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heating_columns = [\n",
    "    \"2D_Heating_power_[Wh]\",\n",
    "    \"4D_Heating_power_[Wh]\",\n",
    "    \"4G_Heating_power_[Wh]\",\n",
    "    \"7D_Heating_power_[Wh]\",\n",
    "]\n",
    "\n",
    "# Calculate daily heating consumption in kWh\n",
    "daily_cons_measure_kWh = (\n",
    "    boundaries[heating_columns].resample(\"D\").sum().sum(axis=1) / 1000\n",
    ")\n",
    "daily_cons_measure_kWh.name = \"Total_heating_consumption_[kWh]\"\n",
    "\n",
    "# Calculate hourly heating consumption in kWh\n",
    "hourly_cons_measure_kWh = boundaries[heating_columns].sum(axis=1) / 1000\n",
    "hourly_cons_measure_kWh.name = \"Total_heating_energy_[kWh]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load idf and add systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from energytool.building import Building, SimuOpt\n",
    "from energytool.system import HeaterSimple, AirHandlingUnit, Sensor, ZoneThermostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building = Building(idf_path=Path(TUTORIAL_DIR) / \"resources/model_v0_store_op.idf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define zone for heating and temperature sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal_zones = [\"R4:4G\", \"R4:4D\", \"R2:2D\", \"R7:7D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "building.add_system(HeaterSimple(name=\"gaz_boiler\", zones=thermal_zones, cop=1))\n",
    "\n",
    "building.add_system(\n",
    "    AirHandlingUnit(\n",
    "        name=\"Extraction_fan\",\n",
    "        zones=thermal_zones,\n",
    "        ach=0.7,\n",
    "        fan_energy_coefficient=0.23,  # Wh/m3\n",
    "        heat_recovery_efficiency=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "building.add_system(\n",
    "    Sensor(\n",
    "        name=\"Hobos\", variables=\"Zone Operative Temperature\", key_values=thermal_zones\n",
    "    )\n",
    ")\n",
    "\n",
    "building.add_system(\n",
    "    Sensor(\n",
    "        name=\"meteo\", variables=\"Site Outdoor Air Drybulb Temperature\", key_values=\"*\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Step 1 — Initial Simulation and Error Evaluation\n",
    "\n",
    "In this step, we run the initial EnergyPlus simulation of the building using the default modeling assumptions (e.g., standard weather file, standard indoor temperature schedules, and system operation).\n",
    "\n",
    "The outputs are compared to the measured data over the heating season, using key error metrics recommended by **ASHRAE Guideline 14** and **IPMVP**:\n",
    "\n",
    "- **NMBE** (Normalized Mean Bias Error): assesses bias in predictions  \n",
    "- **CV(RMSE)** (Coefficient of Variation of the Root Mean Squared Error): evaluates the spread of the prediction errors  \n",
    "\n",
    "Both metrics are calculated on:\n",
    "- **Monthly** aggregated heating energy\n",
    "- **Hourly** heating demand profile\n",
    "\n",
    "We also visually compare:\n",
    "- The **simulated heating energy** vs. **measured boiler output**  \n",
    "- The **simulated indoor temperatures** vs. **measured temperatures**    for the 4D apartment (reference unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_opt = {\n",
    "    SimuOpt.EPW_FILE.value: Path(TUTORIAL_DIR) / r\"FRA_Bordeaux.075100_IWEC.epw\",\n",
    "    SimuOpt.OUTPUTS.value: \"SYSTEM|SENSOR\",\n",
    "    SimuOpt.START.value: \"2021-07-01 00:00\",\n",
    "    SimuOpt.STOP.value: \"2022-06-30 23:00\",\n",
    "    SimuOpt.VERBOSE.value: \"v\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sim = building.simulate(parameter_dict=None, simulation_options=sim_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sim_heating_kWh = (init_sim[\"HEATING_Energy_[J]\"] / 3.6e6).loc[\"2021-10\":\"2022-04\"]\n",
    "\n",
    "to_plot = pd.concat(\n",
    "    [\n",
    "        daily_cons_measure_kWh,\n",
    "        sim_heating_kWh.resample(\"D\").sum(),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "for dat in to_plot.columns:\n",
    "    fig.add_trace(go.Bar(x=init_sim.index, y=to_plot[dat], name=dat))\n",
    "\n",
    "fig.update_layout(dict(title=\"Heating Energy [kWh]\", yaxis_title=\"Energy [kWh]\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "to_plot = pd.concat(\n",
    "    [boundaries[\"T_4D\"], init_sim[\"R4:4D_Zone Operative Temperature\"]], axis=1\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "for dat in to_plot.columns:\n",
    "    fig.add_trace(go.Scatter(x=init_sim.index, y=to_plot[dat], name=dat))\n",
    "\n",
    "fig.update_layout(\n",
    "    dict(title=\"Appartment 4D - Operative temperature\", yaxis_title=\"Temperature [°C]\")\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from corrai.metrics import cv_rmse, nmbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_heating_kWh = hourly_cons_measure_kWh.loc[\"2021-10\":\"2022-04\"]\n",
    "\n",
    "# --- Hourly results---\n",
    "sim_hourly = sim_heating_kWh.resample(\"h\").sum()\n",
    "measured_hourly = measured_heating_kWh.resample(\"h\").sum()\n",
    "\n",
    "nmbe_hourly = nmbe(sim_hourly, measured_hourly)\n",
    "cv_rmse_hourly = cv_rmse(sim_hourly, measured_hourly)\n",
    "r2_hourly = r2_score(sim_hourly, measured_hourly)\n",
    "\n",
    "# --- Monthly results ---\n",
    "sim_monthly = sim_heating_kWh.resample(\"ME\").sum()\n",
    "measured_monthly = measured_heating_kWh.resample(\"ME\").sum()\n",
    "\n",
    "nmbe_monthly = nmbe(sim_monthly, measured_monthly)\n",
    "cv_rmse_monthly = cv_rmse(sim_monthly, measured_monthly)\n",
    "r2_monthly = r2_score(sim_monthly, measured_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hourly comparison:\")\n",
    "print(f\"  NMBE:    {nmbe_hourly / 100:.2%}\")\n",
    "print(f\"  CV(RMSE): {cv_rmse_hourly / 100:.2%}\")\n",
    "print(f\"  R²:      {r2_hourly:.3f}\")\n",
    "\n",
    "print(\"\\nMonthly comparison:\")\n",
    "print(f\"  NMBE:    {nmbe_monthly / 100:.2%}\")\n",
    "print(f\"  CV(RMSE): {cv_rmse_monthly / 100:.2%}\")\n",
    "print(f\"  R²:      {r2_monthly:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion on the intial model performance\n",
    "\n",
    "The initial simulation results show a **very poor agreement** with the measured data.\n",
    "\n",
    "Although the **seasonal trend** of heating demand is somewhat reproduced, the **magnitude of simulated heating needs is consistently underestimated by about 50%**.\n",
    "\n",
    "In particular:\n",
    "- Simulated indoor temperatures during winter are **higher than those actually measured**, despite using a heating setpoint of 22°C.\n",
    "- Heating needs are much **lower than expected**, despite colder simulated temperatures.\n",
    "\n",
    "These results indicate that the model, in its current state, **cannot be used for performance assessment or comparison with measured data** from the 2021–2022 monitoring campaign.\n",
    "\n",
    "This is not unexpected: both **weather data** and **indoor temperature assumptions** are too far from actual conditions. While the model may qualitatively reflect the building’s behavior, its predictive capability is insufficient.\n",
    "\n",
    "> In the next step, we will **replace key assumptions** (notably weather and indoor temperature schedules) with actual measurements, to test whether this adjustment alone reduces the prediction error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Step 2 — Adjustment Using Measured Inputs\n",
    "\n",
    "To improve the model’s realism, we now replace default inputs with **measured data** from the monitoring campaign:\n",
    "\n",
    "- A **custom historical weather file** (based on ERA5 reanalysis) replaces the standard TRY file.\n",
    "- The **measured indoor temperatures** for each monitored apartment are used as **operative temperature setpoints** in the model.\n",
    "\n",
    "> These adjustments should help isolate the impact of model assumptions (e.g., envelope performance, internal gains) from errors due to incorrect boundary conditions.\n",
    "\n",
    "We will simulate the same period again and evaluate the new errors compared to measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building.add_system(\n",
    "    ZoneThermostat(\n",
    "        name=\"2D_thermos\",\n",
    "        zones=\"R2:2D\".upper(),\n",
    "        heating_time_series=boundaries.T_2D,\n",
    "        add_schedules_output_variables=True,\n",
    "        overwrite_heating_availability=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "building.add_system(\n",
    "    ZoneThermostat(\n",
    "        name=\"4D_thermos\",\n",
    "        zones=\"R4:4D\".upper(),\n",
    "        heating_time_series=boundaries.T_4D,\n",
    "        add_schedules_output_variables=True,\n",
    "        overwrite_heating_availability=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "building.add_system(\n",
    "    ZoneThermostat(\n",
    "        name=\"4G_thermos\",\n",
    "        zones=\"R4:4G\".upper(),\n",
    "        heating_time_series=boundaries.T_4G,\n",
    "        add_schedules_output_variables=True,\n",
    "        overwrite_heating_availability=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "building.add_system(\n",
    "    ZoneThermostat(\n",
    "        name=\"7D_thermos\",\n",
    "        zones=\"R7:7D\".upper(),\n",
    "        heating_time_series=boundaries.T_7D,\n",
    "        add_schedules_output_variables=True,\n",
    "        overwrite_heating_availability=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_opt = {\n",
    "    SimuOpt.EPW_FILE.value: Path(TUTORIAL_DIR) / r\"pessac_2021_07_2022_06.epw\",\n",
    "    SimuOpt.OUTPUTS.value: \"SYSTEM|SENSOR\",\n",
    "    SimuOpt.START.value: \"2021-07-01 00:00\",\n",
    "    SimuOpt.STOP.value: \"2022-06-30 23:00\",\n",
    "    SimuOpt.VERBOSE.value: \"v\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_sim = building.simulate(parameter_dict=None, simulation_options=sim_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_heating_kWh = (adjusted_sim[\"HEATING_Energy_[J]\"] / 3.6e6).loc[\"2021-10\":\"2022-04\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "to_plot = pd.concat(\n",
    "    [daily_cons_measure_kWh, sim_heating_kWh.resample(\"1D\").sum()], axis=1\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "for dat in to_plot.columns:\n",
    "    fig.add_trace(go.Bar(x=adjusted_sim.index, y=to_plot[dat], name=dat))\n",
    "\n",
    "fig.update_layout(dict(title=\"Heating Energy [kWh]\", yaxis_title=\"Energy [kWh]\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "to_plot = pd.concat(\n",
    "    [boundaries[\"T_4D\"], adjusted_sim[\"R4:4D_Zone Operative Temperature\"]], axis=1\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "for dat in to_plot.columns:\n",
    "    fig.add_trace(go.Scatter(x=adjusted_sim.index, y=to_plot[dat], name=dat))\n",
    "\n",
    "fig.update_layout(\n",
    "    dict(title=\"Appartment 4D - Operative temperature\", yaxis_title=\"Temperature [°C]\")\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_heating_kWh = hourly_cons_measure_kWh.loc[\"2021-10\":\"2022-04\"]\n",
    "\n",
    "# --- Hourly results---\n",
    "sim_hourly = sim_heating_kWh.resample(\"h\").sum()\n",
    "measured_hourly = measured_heating_kWh.resample(\"h\").sum()\n",
    "\n",
    "nmbe_hourly = nmbe(sim_hourly, measured_hourly)\n",
    "cv_rmse_hourly = cv_rmse(sim_hourly, measured_hourly)\n",
    "r2_hourly = r2_score(sim_hourly, measured_hourly)\n",
    "\n",
    "# --- Monthly results ---\n",
    "sim_monthly = sim_heating_kWh.resample(\"ME\").sum()\n",
    "measured_monthly = measured_heating_kWh.resample(\"ME\").sum()\n",
    "\n",
    "nmbe_monthly = nmbe(sim_monthly, measured_monthly)\n",
    "cv_rmse_monthly = cv_rmse(sim_monthly, measured_monthly)\n",
    "r2_monthly = r2_score(sim_monthly, measured_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hourly comparison:\")\n",
    "print(f\"  NMBE:    {nmbe_hourly / 100:.2%}\")\n",
    "print(f\"  CV(RMSE): {cv_rmse_hourly / 100:.2%}\")\n",
    "print(f\"  R²:      {r2_hourly:.3f}\")\n",
    "\n",
    "print(\"\\nMonthly comparison:\")\n",
    "print(f\"  NMBE:    {nmbe_monthly / 100:.2%}\")\n",
    "print(f\"  CV(RMSE): {cv_rmse_monthly / 100:.2%}\")\n",
    "print(f\"  R²:      {r2_monthly:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion on the adjusted simulation\n",
    "\n",
    "The adjusted simulation confirms the concerns raised in Step 1.\n",
    "\n",
    "By using the measured indoor temperatures as operative temperature setpoints, we expected the simulated and measured temperatures to closely align—especially during winter. However, the simulated temperatures often exceed the measured ones, suggesting that:\n",
    "\n",
    "- **Envelope heat losses (transmission and air exchange) are underestimated**, and/or\n",
    "- **Internal and solar gains are overestimated** in the model.\n",
    "\n",
    "In terms of energy demand:\n",
    "\n",
    "- The **heating needs remain significantly underestimated** (NMBE around -60%), even with accurate boundary conditions.\n",
    "- The **CV(RMSE)** slightly improves on an hourly basis, indicating a modest improvement in capturing day-to-day dynamics.\n",
    "- However, the overall magnitude of the error confirms that the model still lacks realism in its current state.\n",
    "\n",
    "> These results highlight the need to move beyond simply replacing inputs. The next step consists of systematically identifying the model assumptions that most influence the simulation error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Step 3 — Sensitivity Analysis to Identify Key Uncertainties\n",
    "\n",
    "In this step, we aim to understand which model assumptions have the greatest impact on the mismatch between simulation and measurement.\n",
    "\n",
    "We use the **Morris method** (a global sensitivity analysis technique) to evaluate how uncertainty in selected parameters propagates to simulation outputs. See Chapter 2 of energytool for more info on sensitivity analyses.\n",
    "Specifically, we focus on the **RMSE between simulated and measured heating demand**, during the winter period (January–February 2022), as the main calibration objective.\n",
    "\n",
    "The parameters analyzed include:\n",
    "\n",
    "- Glazing thermal conductivity and solar gain factor\n",
    "- Mechanical ventilation air change rates\n",
    "- Thermal conductivity of insulation materials\n",
    "- Infiltration rates\n",
    "- Internal gains (equipment loads)\n",
    "- Thermal capacity of materials\n",
    "\n",
    "Each parameter is varied within a realistic uncertainty range, and a set of simulations is run to explore their effects.\n",
    "\n",
    "> This analysis helps prioritize which parameters should be targeted in the calibration phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from corrai.base.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain_param_List = [\n",
    "    {\n",
    "        Parameter.NAME: \"UFactor\",\n",
    "        Parameter.INTERVAL: [2.5, 5],\n",
    "        Parameter.TYPE: \"Real\",\n",
    "    },\n",
    "    {\n",
    "        Parameter.NAME: \"SHGC\",\n",
    "        Parameter.INTERVAL: [0.2, 0.65],\n",
    "        Parameter.TYPE: \"Real\",\n",
    "    },\n",
    "    {\n",
    "        Parameter.NAME: \"ACH\",\n",
    "        Parameter.INTERVAL: [0.3, 1.5],\n",
    "        Parameter.TYPE: \"Real\",\n",
    "    },\n",
    "    {\n",
    "        Parameter.NAME: \"idf.Material.Concrete Block (Heavyweight)_.2.Specific_Heat\",\n",
    "        Parameter.INTERVAL: [100, 840 + 1.5 * 840],\n",
    "        Parameter.TYPE: \"Real\",\n",
    "    },\n",
    "    {\n",
    "        Parameter.NAME: \"idf.Material.Rock wool - at 10C degrees_.16.Conductivity\",\n",
    "        Parameter.INTERVAL: [0.028, 0.05],\n",
    "        Parameter.TYPE: \"Real\",\n",
    "    },\n",
    "    {\n",
    "        Parameter.NAME: \"Infilt_appart\",\n",
    "        Parameter.INTERVAL: [0.004721 - 0.3 * 0.004721, 0.004721 + 0.3 * 0.004721],\n",
    "        Parameter.TYPE: \"Real\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain_param_List, parameter_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In energy modeling, some parameters in the simulation affect **multiple objects or fields** simultaneously.\n",
    "\n",
    "For example:\n",
    "- A single parameter like `\"Insulation_Therm_Conductivity\"` might need to update the **thermal conductivity** of several different insulation materials in the IDF file.\n",
    "- A user-defined parameter like `\"Infilt_appart\"` could refer to **air infiltration rates** in multiple apartment zones.\n",
    "\n",
    "To handle this, we use a flexible system called `param_mappings` which **maps a user-defined parameter name** (used in sensitivity analysis or optimization) to one or more actual simulation inputs (IDF paths, system variables, etc.).\n",
    "\n",
    "It allows us to:\n",
    "\n",
    "- Abstract complex model modifications into a **single high-level parameter**\n",
    "- Apply the same value to **multiple targets** in the model\n",
    "- Handle **categorical parameters** that translate into multiple changes (e.g., control strategies or weather files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mappings = {\n",
    "    \"Infilt_appart\": [\n",
    "        \"idf.ZoneInfiltration:DesignFlowRate.R4:4G Infiltration.Design_Flow_Rate\",\n",
    "        \"idf.ZoneInfiltration:DesignFlowRate.R4:4D Infiltration.Design_Flow_Rate\",\n",
    "        \"idf.ZoneInfiltration:DesignFlowRate.R2:2D Infiltration.Design_Flow_Rate\",\n",
    "        \"idf.ZoneInfiltration:DesignFlowRate.R7:7D Infiltration.Design_Flow_Rate\",\n",
    "    ],\n",
    "    \"UFactor\": [\n",
    "        \"idf.WindowMaterial:SimpleGlazingSystem.Simple Vitrage_loggia - 1001.UFactor\",\n",
    "        \"idf.WindowMaterial:SimpleGlazingSystem.Simple Vitrage_ext - 1002.UFactor\",\n",
    "        \"idf.WindowMaterial:SimpleGlazingSystem.Simple Vitrage_ext - 1003.UFactor\",\n",
    "    ],\n",
    "    \"SHGC\": [\n",
    "        \"idf.WindowMaterial:SimpleGlazingSystem.Simple Vitrage_loggia - 1001.Solar_Heat_Gain_Coefficient\",\n",
    "        \"idf.WindowMaterial:SimpleGlazingSystem.Simple Vitrage_ext - 1002.Solar_Heat_Gain_Coefficient\",\n",
    "        \"idf.WindowMaterial:SimpleGlazingSystem.Simple Vitrage_ext - 1003.Solar_Heat_Gain_Coefficient\",\n",
    "    ],\n",
    "    \"ACH\": [\n",
    "        \"idf.DesignSpecification:OutdoorAir.R4:4G.Outdoor_Air_Flow_Air_Changes_per_Hour\",\n",
    "        \"idf.DesignSpecification:OutdoorAir.R4:4D.Outdoor_Air_Flow_Air_Changes_per_Hour\",\n",
    "        \"idf.DesignSpecification:OutdoorAir.R2:2D.Outdoor_Air_Flow_Air_Changes_per_Hour\",\n",
    "        \"idf.DesignSpecification:OutdoorAir.R7:7D.Outdoor_Air_Flow_Air_Changes_per_Hour\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell show an example of a resulting dictionnary of parameters values using this parameter mapping: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrai.learning.sampling import expand_parameter_dict\n",
    "\n",
    "param_init_values = {\n",
    "    param[Parameter.NAME]: param[Parameter.INTERVAL][0]\n",
    "    for param in uncertain_param_List\n",
    "}\n",
    "expand_parameter_dict(param_init_values, param_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from corrai.sensitivity import SAnalysis, Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sa_analysis = SAnalysis(\n",
    "    parameters_list=uncertain_param_List,\n",
    "    method=Method.MORRIS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sa_analysis.draw_sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sa_analysis.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_opt_SA = {\n",
    "    SimuOpt.EPW_FILE.value: Path(TUTORIAL_DIR) / r\"pessac_2021_07_2022_06.epw\",\n",
    "    SimuOpt.OUTPUTS.value: \"SYSTEM|SENSOR\",\n",
    "    SimuOpt.START.value: \"2022-01-01 00:00\",\n",
    "    SimuOpt.STOP.value: \"2022-02-05 23:00\",\n",
    "    SimuOpt.VERBOSE.value: \"v\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_analysis.evaluate(\n",
    "    model=building,\n",
    "    simulation_options=sim_opt_SA,\n",
    "    simulate_kwargs={\"param_mapping\": param_mappings},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrai.metrics import cv_rmse, nmbe\n",
    "import numpy as np\n",
    "\n",
    "sa_analysis.analyze(\n",
    "    indicator=\"HEATING_Energy_[J]\",\n",
    "    agg_method=np.sum,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrai.sensitivity import plot_morris_scatter\n",
    "\n",
    "sa_analysis.calculate_sensitivity_indicators()\n",
    "plot_morris_scatter(\n",
    "    salib_res=sa_analysis.sensitivity_results,\n",
    "    title=\"Elementary effects\",\n",
    "    unit=\"J\",\n",
    "    autosize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for sim in sa_analysis.sample_results:\n",
    "    sim[2][\"HEATING_Energy_kWh\"] = sim[2][\"HEATING_Energy_[J]\"] / 3600 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_analysis.analyze(\n",
    "    indicator=\"HEATING_Energy_kWh\",\n",
    "    reference_df=hourly_cons_measure_kWh.loc[\"2022-01-01 00:00\":\"2022-02-05 23:00\"],\n",
    "    agg_method=mean_squared_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plot_morris_scatter(\n",
    "    sa_analysis.sensitivity_results, title=\"Elementary effects\", unit=\"J\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morris Sensitivity Analysis results interpretation\n",
    "\n",
    "The Morris method provides insight into how variations in model parameters affect simulation outputs.\n",
    "\n",
    "Two different outputs were analyzed:\n",
    "- **Total simulated heating demand** over the winter period (January–February 2022)\n",
    "- **RMSE between simulated and measured heating demand**, used as a calibration objective\n",
    "\n",
    "\n",
    "### Simulated Heating Demand\n",
    "\n",
    "The first sensitivity analysis measures how each parameter influences the total predicted heating needs.\n",
    "\n",
    "- Most parameters exhibit a **linear and additive influence**, as indicated by relatively high μ* (mean absolute effect) and low σ (standard deviation).\n",
    "- Key influential parameters include:\n",
    "  - **Glazing conductivity**\n",
    "  - **Solar heat gain coefficient (SHGC)**\n",
    "  - **Ventilation air change rate**\n",
    "  - **Envelope insulation conductivity**\n",
    "  - **Internal gains from equipment**\n",
    "\n",
    "- Parameters such as **loggia airflow rate** and **thermal capacity of materials** have a minimal impact on the total heating needs.\n",
    "\n",
    "### RMSE Between Simulation and Measurement\n",
    "\n",
    "The second analysis focuses on the **error** between the model prediction and measured heating data.\n",
    "- Results show a **stronger non-linearity** and higher interaction effects (high σ values), indicating **complex or non-monotonic relationships**, with similar ranking of parameter importance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Step 4 — Model Calibration\n",
    "\n",
    "Following the sensitivity analysis, we now proceed to calibrate the model by identifying the combination of uncertain parameter values that best minimizes the error between simulation and measurement.\n",
    "\n",
    "The calibration process aims to reduce the discrepancy between:\n",
    "- **Simulated heating demand**, and\n",
    "- **Measured heating demand**, aggregated over the winter period (November to April)\n",
    "\n",
    "---\n",
    "Due to the **non-linear** and potentially **non-monotonic** relationship between parameters and model error (as shown by the Morris analysis), the calibration problem is inherently difficult. Traditional gradient-based optimizers are not well-suited for such problems.\n",
    "\n",
    "We therefore use a **genetic algorithm** — a population-based, stochastic optimization method known for its robustness in complex search spaces.\n",
    "\n",
    "However, running thousands of EnergyPlus simulations can be computationally expensive and time-consuming. To address this, we employ a **surrogate model** (also known as a **metamodel**) that approximates the relationship between input parameters and the RMSE error.\n",
    "\n",
    "The surrogate model is trained on a sample of EnergyPlus simulations (e.g., from the Morris experiment), and then used to:\n",
    "\n",
    "- Quickly estimate the error for new parameter combinations\n",
    "- Guide the optimization algorithm toward promising regions of the parameter space\n",
    "- Reduce the number of expensive full simulations required\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelSampler` from corrai.learning can be used first, to: \n",
    "\n",
    "- Generate parameter samples using a **space-filling design** (e.g., Latin Hypercube)\n",
    "- Interface with the simulation model to **run the simulations automatically**\n",
    "- Store both the **sampled parameter sets** and the corresponding **simulation outputs**\n",
    "\n",
    "This class acts as the bridge between your model and the uncertainty exploration needed for sensitivity analysis or surrogate modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corrai.learning.sampling import ModelSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ModelSampler(\n",
    "    parameters=uncertain_param_List,\n",
    "    model=building,\n",
    "    sampling_method=\"LatinHypercube\",\n",
    "    simulation_options=sim_opt_SA,\n",
    "    param_mappings=param_mappings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ModelSampler` class provides two methods for sampling variants: `add_sample` and `draw_sample`. \n",
    "\n",
    "- `add_sample`: This method adds a sample of of size n. This method is useful when you want to build a specific sample incrementally, running systematically simulation for each sampel, progressively adding variants until the desired sample size is reached.\n",
    "\n",
    "- `draw_sample`: This method draws a sample of parameters.It will only select combinations without simulating them. They can be simulated later on, using method `simulate_combinations`.\n",
    "\n",
    "For instance, we could generate 150 simulations using: \n",
    "<code> sampler.add_sample(sample_size=150, seed=42) </code>. \n",
    "\n",
    "Since we simulated 70 combinations for the sensitivity analysis, let's use them instead in this tutorial. Note that 70 simulations for several parameters is not much at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.sample = sa_analysis.sample\n",
    "sampler.sample_results = [sim[2] for sim in sa_analysis.sample_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Surrogate Modeling with `ModelTrainer` and `MultiModelSO`\n",
    "\n",
    "To reduce computational cost during calibration, we use a **surrogate model** (or **metamodel**) — a fast approximation of the simulation model that maps parameter inputs to a specific output (e.g., RMSE).\n",
    "\n",
    "Two tools are available for building and selecting surrogate models:\n",
    "\n",
    "---\n",
    "\n",
    "###  `ModelTrainer` — Train a Single Surrogate\n",
    "\n",
    "The `ModelTrainer` wraps any scikit-learn-compatible regression pipeline and handles:\n",
    "\n",
    "- Splitting training and testing data\n",
    "- Fitting the model to simulation results\n",
    "- Evaluating the prediction error using standard metrics:\n",
    "  - `test_nmbe_score`\n",
    "  - `test_cvrmse_score`\n",
    "\n",
    "### `MultiModelSO` — Comparing and selecting the best surrogate\n",
    "\n",
    "The `MultiModelSO` class allows you to easily compare several surrogate models and automatically select the best-performing one.\n",
    "\n",
    "It provides:\n",
    "\n",
    "- Training of multiple regression models at once:\n",
    "- Linear, polynomial, support vector machines, random forests, neural networks, etc.\n",
    "- Cross-validation for fair model comparison\n",
    "- Automatic selection of the best model based on a scoring metric (e.g., RMSE)\n",
    "- Optional hyperparameter tuning using grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from corrai.learning.model_selection import ModelTrainer, MultiModelSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target **y** (indicator) here is the difference between measured and simulated heating energy comsumption, and our training data set is the simulated sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sim = building.simulate(parameter_dict=None, simulation_options=sim_opt_SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(sampler.sample_results)\n",
    "\n",
    "y_preds = [r[\"HEATING_Energy_kWh\"].sum() for r in sampler.sample_results]\n",
    "y_true = np.full(n, hourly_cons_measure_kWh.loc[\"2022-01-01\":\"2022-02-05\"].sum())\n",
    "\n",
    "mse_list = [mean_squared_error([true], [pred]) for true, pred in zip(y_true, y_preds)]\n",
    "y = pd.Series(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(sampler.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSO = MultiModelSO(fine_tuning=False)\n",
    "trainer = ModelTrainer(modelSO)\n",
    "trainer.train(X=x_train_df, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the r-score of the best model on prediciton data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_pipe.score(trainer.x_test, trainer.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict the heating energy on new samples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.draw_sample(sample_size=1000, seed=42)\n",
    "x_pred_df = pd.DataFrame(sampler.not_simulated_samples)\n",
    "modelSO.predict(x_pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Using the Surrogate Model\n",
    "\n",
    "After training and evaluating several surrogate models, we now select the **best-performing one** to use as a fast approximation of the simulation model.\n",
    "\n",
    "This surrogate will be used to **find the combination of parameters** that minimizes the error between the model and the measurements.\n",
    "\n",
    "We define an **objective function** that takes a vector of input parameters and returns the **predicted RMSE** from the surrogate model.\n",
    "\n",
    "This function is passed to `scipy.optimize.minimize`, which performs a local search for the minimum error.\n",
    "\n",
    "- The optimization is performed in the **parameter space** defined during sampling.\n",
    "- The surrogate is used instead of the full simulation to keep the process fast.\n",
    "- The result is a calibrated set of parameters that minimize the model-measurement discrepancy, according to the surrogate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def _objective_function(x):\n",
    "    x_df = pd.DataFrame([x], columns=[p[Parameter.NAME] for p in uncertain_param_List])\n",
    "    y_pred = trainer.model_pipe.predict(x_df)\n",
    "    return float(np.asarray(y_pred).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = differential_evolution(\n",
    "    _objective_function,\n",
    "    bounds=[tuple(param[Parameter.INTERVAL]) for param in uncertain_param_List],\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names = [param[Parameter.NAME] for param in uncertain_param_List]\n",
    "parameter_dict = {param_name: res.x[i] for i, param_name in enumerate(parameter_names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate with this set of values for our parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_calibrated = building.simulate(\n",
    "    parameter_dict=parameter_dict,\n",
    "    simulation_options=sim_opt,\n",
    "    param_mapping=param_mappings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "sim_daily = sim_calibrated[\"HEATING_Energy_[J]\"].resample(\"D\").sum() / 3600 / 1000\n",
    "ref_daily = hourly_cons_measure_kWh.resample(\"D\").sum()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        name=\"Simulation\",\n",
    "        mode=\"lines\",\n",
    "        x=sim_daily.index,\n",
    "        y=sim_daily,\n",
    "        line=dict(color=\"green\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        name=\"Measurement\",\n",
    "        mode=\"lines\",\n",
    "        x=ref_daily.index,\n",
    "        y=ref_daily,\n",
    "        line=dict(color=\"crimson\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Comparison Simulation vs Measurement\",\n",
    "    yaxis_title=\"Heating [kWh/day]\",\n",
    "    template=\"simple_white\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sim_energy_kWh = sim_calibrated[\"HEATING_Energy_[J]\"] / 3600 / 1000\n",
    "measured_energy_kWh = hourly_cons_measure_kWh\n",
    "\n",
    "# --- Resample ---\n",
    "sim_hourly = sim_energy_kWh.resample(\"h\").sum()\n",
    "measured_hourly = measured_energy_kWh.resample(\"h\").sum()\n",
    "\n",
    "sim_daily = sim_energy_kWh.resample(\"D\").sum()\n",
    "measured_daily = measured_energy_kWh.resample(\"D\").sum()\n",
    "\n",
    "sim_monthly = sim_energy_kWh.resample(\"ME\").sum()\n",
    "measured_monthly = measured_energy_kWh.resample(\"ME\").sum()\n",
    "\n",
    "# --- Metrics ---\n",
    "nmbe_hourly = nmbe(sim_hourly, measured_hourly)\n",
    "cvrmse_hourly = cv_rmse(sim_hourly, measured_hourly)\n",
    "r2_hourly = r2_score(sim_hourly, measured_hourly)\n",
    "\n",
    "nmbe_daily = nmbe(sim_daily, measured_daily)\n",
    "cvrmse_daily = cv_rmse(sim_daily, measured_daily)\n",
    "r2_daily = r2_score(sim_daily, measured_daily)\n",
    "\n",
    "nmbe_monthly = nmbe(sim_monthly, measured_monthly)\n",
    "cvrmse_monthly = cv_rmse(sim_monthly, measured_monthly)\n",
    "r2_monthly = r2_score(sim_monthly, measured_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Hourly comparison:\")\n",
    "print(f\"  NMBE:     {nmbe_hourly / 100:.2%}\")\n",
    "print(f\"  CV(RMSE): {cvrmse_hourly / 100:.2%}\")\n",
    "print(f\"  R²:       {r2_hourly:.3f}\")\n",
    "\n",
    "print(\"Daily comparison:\")\n",
    "print(f\"  NMBE:     {nmbe_daily / 100:.2%}\")\n",
    "print(f\"  CV(RMSE): {cvrmse_daily / 100:.2%}\")\n",
    "print(f\"  R²:       {r2_daily:.3f}\")\n",
    "\n",
    "print(\"Monthly comparison:\")\n",
    "print(f\"  NMBE:     {nmbe_monthly / 100:.2%}\")\n",
    "print(f\"  CV(RMSE): {cvrmse_monthly / 100:.2%}\")\n",
    "print(f\"  R²:       {r2_monthly:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "The calibration process has shown some promising signs, but also highlighted clear limitations of the current model.\n",
    "\n",
    "- The calibrated results are better centered, and on average the model **underestimates the heating demand**.\n",
    "- The reduction in CV(RMSE) at the monthly scale suggests that the **overall seasonal dynamics are reasonably captured**.\n",
    "- However, at the **hourly level**, the error remains significant — which undermines the usefulness of the model for detailed thermal simulation.\n",
    "\n",
    "All optimized parameter values ended up at or near the **limits of their acceptable ranges**. This is not a good sign:\n",
    "> It likely indicates that the optimization algorithm attempted to escape the defined bounds to further reduce the error — implying that the model is even more inaccurate than initially expected.\n",
    "\n",
    "Additionally, our surrogate models were trained on a relatively **small dataset** (a few dozen simulations), which is likely insufficient given the **high dimensionality** of the parameter space.\n",
    "\n",
    "**Next steps**\n",
    "\n",
    "- Increase the number of simulations to better explore the parameter space.\n",
    "- Re-express or simplify the model if possible.\n",
    "- Consider identifying the most sensitive parameters and fixing the least influential ones.\n",
    "\n",
    "In its current state, the model should **not** be used to explain measured data from 2021–2022 or to draw strong conclusions. Further refinement and validation are needed before it becomes a reliable predictive tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
